---
title: "R Notebook"
output: html_notebook
---

```{r}
library(caret)
library(nnet)
library(MLmetrics)
library(gbm)
library(randomForest)
library(xgboost)
library(Matrix)
```


```{r}
df <- read.csv("data_for_modeling_clean.csv")
head(df)
```

```{r}
# drop duplicates
df <- df[!duplicated(df), ]
dim(df)
```

```{r}
str(df)
```

### Change the categorical data into factors
```{r}
categorical_var <- c("MONTH", "DAY_OF_WEEK", "DEP_DEL15", "DISTANCE_GROUP", 
                      "SEGMENT_NUMBER", "DEP_TIME_START")
df[categorical_var] <- lapply(df[categorical_var], as.factor)
str(df)
```


## 1. Neural Network

```{r}
neurons <- c(3, 5, 7)  # Number of hidden neurons
lambda <- c(0.001, 0.01, 0.1)  # Regularization (decay)
K <- 5  # Number of folds for cross-validation

# Store results
results <- expand.grid(size = neurons, decay = lambda, Accuracy = NA, 
                       Precision = NA, Recall = NA, F1 = NA)

n <- nrow(df)
y <- df$DEP_DEL15  # Target variable

# Convert target variable to factor with explicit levels
df$DEP_DEL15 <- factor(df$DEP_DEL15, levels = c("0", "1"))

set.seed(1234)
cv_folds <- sample(rep(1:K, length.out = n))  # Randomly assign folds

for (i in 1:nrow(results)) {
  size <- results$size[i]
  decay <- results$decay[i]

  accuracy_list <- numeric(K)
  precision_list <- numeric(K)
  recall_list <- numeric(K)
  f1_list <- numeric(K)

  for (fold in 1:K) {
    train_idx <- which(cv_folds != fold)
    test_idx <- which(cv_folds == fold)
    
    # Train Neural Network
    nn_model <- nnet(DEP_DEL15 ~ ., data = df[train_idx, ], size = size, 
                     decay = decay, maxit = 500, trace = FALSE)

    # Predict Class Labels
    nn_probs <- predict(nn_model, df[test_idx, ], type = "class")

    # Ensure Factor Levels Match
    nn_probs <- factor(nn_probs, levels = levels(df$DEP_DEL15))

    # Compute Confusion Matrix
    conf_matrix <- confusionMatrix(nn_probs, df$DEP_DEL15[test_idx], positive = "1")

    # Extract Performance Metrics
    accuracy_list[fold] <- conf_matrix$overall["Accuracy"]
    precision_list[fold] <- conf_matrix$byClass["Precision"]
    recall_list[fold] <- conf_matrix$byClass["Recall"]
    f1_list[fold] <- F1_Score(as.numeric(as.character(nn_probs)), 
                              as.numeric(as.character(df$DEP_DEL15[test_idx])), 
                              positive = "1")
  }

  # Store the averaged performance metrics across folds
  results$Accuracy[i] <- mean(accuracy_list)
  results$Precision[i] <- mean(precision_list)
  results$Recall[i] <- mean(recall_list)
  results$F1[i] <- mean(f1_list)
}
```

```{r}
results
```

The best one that stabilize the precision and recall is when size = 7, and decay = 0.01. Eventhough it is not the best one, but we'll try to fit using other models as well.

## 2. Tree
```{r}
library(rpart)
control <- rpart.control(minbucket = 3, cp = 0.0001, maxsurrogate = 0, usesurrogate = 0, xval = 10)
tree_model <- rpart(DEP_DEL15~., data = df, method = "class", control = control)
plotcp(tree_model)
```

```{r}
best_cp <- tree_model$cptable[which.min(tree_model$cptable[, "xerror"]), "CP"]
prune_tree <- prune(tree_model, cp = best_cp)
prune_tree$variable.importance
```

```{r}
cp_table_prune_tree = prune_tree$cptable[nrow(prune_tree$cptable),]
cp_table_prune_tree
```

```{r}
missclassified_cv_tree <- cp_table_prune_tree['xerror'] * (1 - max(prop.table(table(df$DEP_DEL15))))
missclassified_cv_tree
```

Misclassified CV by Tree: 1-0.1893946 = 0.8106

```{r}
prune_preds <- predict(prune_tree, df, type = "class")
conf_matrix <- confusionMatrix(prune_preds, df$DEP_DEL15, positive = "1") # positive is the minority class

accuracy <- conf_matrix$overall["Accuracy"]
precision <- conf_matrix$byClass["Precision"]
recall <- conf_matrix$byClass["Recall"]
f1_score <- F1_Score(prune_preds, df$DEP_DEL15, positive = "1")

print(paste("Accuracy:", round(accuracy, 4)))
print(paste("Precision:", round(precision, 4)))
print(paste("Recall:", round(recall, 4)))
print(paste("F1-Score:", round(f1_score, 4)))
```

```{r}
K <- 5
set.seed(123)

cv_folds <- createFolds(df$DEP_DEL15, k = K, list = TRUE)  # Stratified CV

accuracy_list <- numeric(K)
precision_list <- numeric(K)
recall_list <- numeric(K)
f1_list <- numeric(K)

for (fold in 1:K) {
  train_idx <- setdiff(1:nrow(df), cv_folds[[fold]])
  test_idx <- cv_folds[[fold]]
  
  train_data <- df[train_idx, ]
  test_data <- df[test_idx, ]
  
  tree_model <- rpart(DEP_DEL15 ~ ., data = train_data, method = "class", 
                      control = rpart.control(minbucket = 3, cp = 0.0001, 
                                              maxsurrogate = 0, usesurrogate = 0, xval = 10))

  best_cp <- tree_model$cptable[which.min(tree_model$cptable[, "xerror"]), "CP"]
  prune_tree <- prune(tree_model, cp = best_cp)
  
  prune_preds <- predict(prune_tree, test_data, type = "class")
  
  conf_matrix <- confusionMatrix(as.factor(prune_preds), as.factor(test_data$DEP_DEL15), positive = "1")
  
  accuracy_list[fold] <- conf_matrix$overall["Accuracy"]
  precision_list[fold] <- conf_matrix$byClass["Precision"]
  recall_list[fold] <- conf_matrix$byClass["Recall"]
  f1_list[fold] <- F1_Score(as.numeric(as.character(prune_preds)), 
                            as.numeric(as.character(test_data$DEP_DEL15)), 
                            positive = "1") # positive is the minority class. in here it is 1
}

cv_accuracy_tree <- mean(accuracy_list)
cv_precision_tree <- mean(precision_list)
cv_recall_tree <- mean(recall_list)
cv_f1_tree <- mean(f1_list)

print(paste("Decision Tree CV Accuracy:", round(cv_accuracy_tree, 4)))
print(paste("Decision Tree CV Precision:", round(cv_precision_tree, 4)))
print(paste("Decision Tree CV Recall:", round(cv_recall_tree, 4)))
print(paste("Decision Tree CV F1-Score:", round(cv_f1_tree, 4)))
```

Here I try to calculate the precision recall and f1-score by using cross validation inside the cv for tree to make it as an apple to apple comparing with the neural network and other models by using cross validation.

In here I try to give more penalty for misclassifying the minority class. 

```{r}
tree_model_weighted <- rpart(DEP_DEL15 ~ ., data = df, method = "class",
                             control = rpart.control(cp = best_cp),
                             parms = list(loss = matrix(c(0, 2, 1, 0), nrow = 2)))
```



```{r}
tree_model_weighted$cptable[nrow(tree_model_weighted$cptable),]
```

```{r}
weighted_preds <- predict(tree_model_weighted, df, type = "class")
conf_matrix_weighted <- confusionMatrix(weighted_preds, df$DEP_DEL15, positive = "1") # positive is the minority class

accuracy_weighted <- conf_matrix_weighted$overall["Accuracy"]
precision_weighted <- conf_matrix_weighted$byClass["Precision"]
recall_weighted <- conf_matrix_weighted$byClass["Recall"]
f1_score_weighted <- F1_Score(weighted_preds, df$DEP_DEL15, positive = "1")

print(paste("Accuracy:", round(accuracy_weighted, 4)))
print(paste("Precision:", round(precision_weighted, 4)))
print(paste("Recall:", round(recall_weighted, 4)))
print(paste("F1-Score:", round(f1_score_weighted, 4)))
```

Accuracy is not as high as the previous tree, but we can predict the minority class better right now, showed by the recall score of 15%, which increase by 10% with the previous tree fitted, but as a result, there is a trade-off with the precision score. We will try several different model to see the impact of it.


## 3. Boosted Tree
```{r}
str(df$DEP_DEL15)
```

```{r}
gbm1 <- gbm(as.numeric(as.character(df$DEP_DEL15))~., data = df, distribution = "bernoulli", n.trees = 3000,
            shrinkage = 0.1, interaction.depth = 3, bag.fraction = 0.5, train.fraction = 1,
            n.minobsinnode = 10, cv.folds = 5, keep.data = TRUE, verbose = FALSE)
best.iter <- gbm.perf(gbm1, method = "cv")
```

```{r}
best.iter
```

So, the best number of tree based on the cross validation is when having 450 number of trees.

```{r}
summary(gbm1, n.trees = best.iter)
```

Quite similar variable importance with the single tree model. DEP_TIME_START and PRCP still the top 2 important variables based on the gradient boosted tree.

```{r}
gbm1_prob <- predict(gbm1, df, n.trees = best.iter, type = "response")
gbm1_pred <- ifelse(gbm1_prob > 0.5, 1, 0)
conf_matrix_gbm1 <- confusionMatrix(as.factor(gbm1_pred), as.factor(df$DEP_DEL15), positive = "1")

accuracy_gbm1 <- conf_matrix_gbm1$overall["Accuracy"]
precision_gbm1 <- conf_matrix_gbm1$byClass["Precision"]
recall_gbm1 <- conf_matrix_gbm1$byClass["Recall"]
f1_score_gbm1 <- F1_Score(gbm1_pred, df$DEP_DEL15, positive = "1")

print(paste("Accuracy:", round(accuracy_gbm1, 4)))
print(paste("Precision:", round(precision_gbm1, 4)))
print(paste("Recall:", round(recall_gbm1, 4)))
print(paste("F1-Score:", round(f1_score_gbm1, 4)))
```

From the result, it can be seen that the Boosted Tree is still struggling to predict the minority class, showed by the recall score. 

```{r}
threshold <- 0.3  # adjusting the threshold to be predicted as 1
gbm1_pred <- ifelse(gbm1_prob > threshold, 1, 0)

conf_matrix_gbm1 <- confusionMatrix(as.factor(gbm1_pred), as.factor(df$DEP_DEL15), positive = "1")
accuracy_gbm1 <- conf_matrix_gbm1$overall["Accuracy"]
precision_gbm1 <- conf_matrix_gbm1$byClass["Precision"]
recall_gbm1 <- conf_matrix_gbm1$byClass["Recall"]
f1_score_gbm1 <- F1_Score(gbm1_pred, df$DEP_DEL15, positive = "1")

print(paste("Accuracy:", round(accuracy_gbm1, 4)))
print(paste("Precision:", round(precision_gbm1, 4)))
print(paste("Recall:", round(recall_gbm1, 4)))
print(paste("F1-Score:", round(f1_score_gbm1, 4)))
```

By reducing the threshold, it seems that the accuracy doesn't drop too much, but we have a higher recall score, as a result, F1-score also increasing.

#### Try to use class weight on GBM
```{r}
class_weights <- ifelse(df$DEP_DEL15 == 1, 2, 1)  # Adjust ratio (here is 5:1)

gbm2 <- gbm(as.numeric(as.character(df$DEP_DEL15)) ~ ., data = df, 
            distribution = "bernoulli", n.trees = 3000, shrinkage = 0.1, 
            interaction.depth = 3, bag.fraction = 0.5, train.fraction = 1,
            n.minobsinnode = 10, cv.folds = 5, keep.data = TRUE, verbose = FALSE,
            weights = class_weights)
```

```{r}
best.iter2 <- gbm.perf(gbm2, method = "cv")
best.iter2
```

```{r}
gbm2_prob <- predict(gbm2, df, n.trees = best.iter2, type = "response")
gbm2_pred <- ifelse(gbm2_prob > 0.5, 1, 0)
conf_matrix_gbm2 <- confusionMatrix(as.factor(gbm2_pred), as.factor(df$DEP_DEL15), positive = "1")

accuracy_gbm2 <- conf_matrix_gbm2$overall["Accuracy"]
precision_gbm2 <- conf_matrix_gbm2$byClass["Precision"]
recall_gbm2 <- conf_matrix_gbm2$byClass["Recall"]
f1_score_gbm2 <- F1_Score(gbm2_pred, df$DEP_DEL15, positive = "1")

print(paste("Accuracy:", round(accuracy_gbm2, 4)))
print(paste("Precision:", round(precision_gbm2, 4)))
print(paste("Recall:", round(recall_gbm2, 4)))
print(paste("F1-Score:", round(f1_score_gbm2, 4)))
```

By introducing more weights on the minority class for 2:1, it has improved the recall score. 


## 4. Random Forest
```{r}
rf_model <- randomForest(DEP_DEL15 ~ ., data = df, mtry = 3, ntree = 500, importance = TRUE)
```

```{r}
rf_model
```

```{r}
plot(rf_model)
```

- Black line -> total error for all classes
- Red line -> OOB for majority class (class 0)
- Green line -> OOB for minority class (class 1)

Highly bias to predict majority class. In here, I tried to give more weights for the minority class. 

```{r}
# try to give more weights on the minority class
rf_model_weighted <- randomForest(DEP_DEL15 ~ ., data = df, 
                                  mtry = 3, ntree = 500, importance = TRUE, 
                                  classwt = c("0" = 1, "1" = 2))

rf_model_weighted
```

```{r}
# try to give more weights on the minority class
rf_model_weighted <- randomForest(DEP_DEL15 ~ ., data = df, 
                                  mtry = 3, ntree = 500, importance = TRUE, 
                                  classwt = c("0" = 1, "1" = 5))
```
```{r}
rf_model_weighted
```

Even giving more weights doesn't improve the OOB of error estimate. After trying several different models, I think the dataset may lack of something that all of the machine learning model, even the complex one, which is neural network couldn't capture it.

## 5. XGBoost
```{r}
# xgboost need to have matrix as their input
df_matrix <- model.matrix(DEP_DEL15 ~ ., data = df)[,-1]  # Remove intercept
label <- as.numeric(as.character(df$DEP_DEL15)) 

# xgboost format for fitting into the function
dtrain <- xgb.DMatrix(data = df_matrix, label = label)
```

```{r}
params <- list(
  objective = "binary:logistic", 
  eval_metric = "logloss", 
  max_depth = 3,
  eta = 0.1, 
  subsample = 0.8, 
  colsample_bytree = 0.8 
)

xgb_cv <- xgb.cv(
  params = params,
  data = dtrain,
  nrounds = 500, 
  nfold = 5, 
  stratified = TRUE, 
  print_every_n = 10, 
  early_stopping_rounds = 10 
)
```

```{r}
best_nrounds <- xgb_cv$best_iteration
best_nrounds
```

```{r}
xgb_model <- xgboost(
  params = params,
  data = dtrain,
  nrounds = best_nrounds, 
  verbose = 0
)

# predict prob
xgb_probs <- predict(xgb_model, dtrain)

# convert to label
xgb_preds <- ifelse(xgb_probs > 0.5, 1, 0)

conf_matrix_xgb <- confusionMatrix(as.factor(xgb_preds), as.factor(df$DEP_DEL15), positive = "1")

accuracy_xgb <- conf_matrix_xgb$overall["Accuracy"]
precision_xgb <- conf_matrix_xgb$byClass["Precision"]
recall_xgb <- conf_matrix_xgb$byClass["Recall"]
f1_score_xgb <- F1_Score(xgb_preds, df$DEP_DEL15, positive = "1")

print(paste("Accuracy:", round(accuracy_xgb, 4)))
print(paste("Precision:", round(precision_xgb, 4)))
print(paste("Recall:", round(recall_xgb, 4)))
print(paste("F1-Score:", round(f1_score_xgb, 4)))
```

Try weighted one on XGBoost
```{r}
params <- list(
  objective = "binary:logistic",
  eval_metric = "logloss",
  max_depth = 3,
  eta = 0.1,
  subsample = 0.8,
  colsample_bytree = 0.8,
  scale_pos_weight = 2  # 2:1 ratio for class 1
)

xgb_cv_weighted <- xgb.cv(
  params = params,
  data = dtrain,
  nrounds = 300,
  nfold = 5,
  stratified = TRUE,
  print_every_n = 10,
  early_stopping_rounds = 10
)

best_nrounds_weighted <- xgb_cv_weighted$best_iteration
print(paste("Best rounds with weighting:", best_nrounds_weighted))

xgb_model_weighted <- xgboost(
  params = params,
  data = dtrain,
  nrounds = best_nrounds_weighted,  # Use optimal rounds
  verbose = 0
)
```

```{r}
xgb_probs_weighted <- predict(xgb_model_weighted, dtrain)
xgb_preds_weighted <- ifelse(xgb_probs_weighted > 0.5, 1, 0)
conf_matrix_xgb_weighted <- confusionMatrix(as.factor(xgb_preds_weighted), as.factor(df$DEP_DEL15), positive = "1")

accuracy_xgb_weighted <- conf_matrix_xgb_weighted$overall["Accuracy"]
precision_xgb_weighted <- conf_matrix_xgb_weighted$byClass["Precision"]
recall_xgb_weighted <- conf_matrix_xgb_weighted$byClass["Recall"]
f1_score_xgb_weighted <- F1_Score(xgb_preds_weighted, df$DEP_DEL15, positive = "1")

print(paste("Accuracy:", round(accuracy_xgb_weighted, 4)))
print(paste("Precision:", round(precision_xgb_weighted, 4)))
print(paste("Recall:", round(recall_xgb_weighted, 4)))
print(paste("F1-Score:", round(f1_score_xgb_weighted, 4)))
```

